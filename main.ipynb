{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pacotes Necessários "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descomente as linhas desta célula para instalar os pacotes necessários\n",
    "# !pip3 install xgboost\n",
    "# !pip3 install psycopg2\n",
    "# !pip3 install pandas\n",
    "# !pip3 install configparser\n",
    "# !pip3 install scikit-learn\n",
    "# !pip3 install matplotlib\n",
    "# !pip3 install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from configparser import ConfigParser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conexão com a Base e Extração de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para configuração de conexão com parâmetros de acesso presentes no arquivo database.ini\n",
    "# Transforma o arquivo em uma variável de objeto\n",
    "def config(filename='database.ini', section='postgresql'):\n",
    "    \n",
    "    parser = ConfigParser()\n",
    "    parser.read(filename)\n",
    "\n",
    "    db = {}\n",
    "    if parser.has_section(section):\n",
    "        params = parser.items(section)\n",
    "        for param in params:\n",
    "            db[param[0]] = param[1]\n",
    "        print('Configurações carregadas.')\n",
    "    else:\n",
    "        raise Exception('Seção {0} não encontrada no arquivo {1}'.format(section, filename))\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect():\n",
    "    conn = None\n",
    "    try:\n",
    "        params = config()\n",
    "        conn = psycopg2.connect(**params)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        retorno = []\n",
    "\n",
    "        cursor.execute('SELECT * FROM forms')\n",
    "        forms = cursor.fetchall()\n",
    "        cursor.execute(\"SELECT column_name FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = 'forms'\")\n",
    "        colunas = cursor.fetchall()\n",
    "        retorno.append([forms, colunas])\n",
    "\n",
    "        cursor.execute('SELECT * FROM orders')\n",
    "        orders = cursor.fetchall()\n",
    "        cursor.execute(\"SELECT column_name FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = 'orders'\")\n",
    "        colunas = cursor.fetchall()\n",
    "        retorno.append([orders, colunas])\n",
    "\n",
    "        cursor.execute('SELECT * FROM order_items')\n",
    "        items = cursor.fetchall()\n",
    "        cursor.execute(\"SELECT column_name FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = 'order_items'\")\n",
    "        colunas = cursor.fetchall()\n",
    "        retorno.append([items, colunas])\n",
    "\n",
    "        cursor.close()\n",
    "        return retorno\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "    finally:\n",
    "        if conn is not None:\n",
    "            conn.close()\n",
    "            print('Conexão encerrada.')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    retorno = connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atribuindo bases de dados a variáveis\n",
    "forms = pd.DataFrame(retorno[0][0])\n",
    "forms.columns = [item for sublist in retorno[0][1] for item in sublist]\n",
    "\n",
    "orders = pd.DataFrame(retorno[1][0])\n",
    "orders.columns = [item for sublist in retorno[1][1] for item in sublist]\n",
    "\n",
    "order_items = pd.DataFrame(retorno[2][0])\n",
    "order_items.columns = [item for sublist in retorno[2][1] for item in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Manipulação de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remoção de colunas\n",
    "forms = forms.drop(['id_cliente','data','sistema_operacional','navegador','localizacao','locale','cidade','utm_source',\n",
    "'caracteristica','tempo_procedimento','efeitos_desejados','estado','procedimentos'], axis = 1)\n",
    "\n",
    "orders = orders[['id_pedido','target']]\n",
    "\n",
    "order_items = order_items[['id_pedido','id_form']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionando apenas os valores únicos da coluna 'id_form' da tabela 'order_items'\n",
    "items_form = order_items.drop_duplicates(subset = ['id_form'])\n",
    "# Left join da tabela 'forms' com a 'items_form' seguido de left join da tabela resultante com a tabela 'orders'. \n",
    "# df é a base de dados resultante\n",
    "df = forms.merge(items_form, \n",
    "                 on = 'id_form', \n",
    "                 how = 'left').merge(orders, \n",
    "                                     on = 'id_pedido', \n",
    "                                     how = 'left').drop(['id_form','id_pedido'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lidando com NAs\n",
    "df.target.fillna(0, inplace = True)\n",
    "df.dropna(axis = 0, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformação de variáveis\n",
    "[df.tipo_cabelo, codes_tipo_cabelo] = pd.factorize(df.tipo_cabelo, sort = True)\n",
    "[df.comprimento, codes_comprimento] = pd.factorize(df.comprimento, sort = True)\n",
    "[df.tipo_fios, codes_tipo_fios] = pd.factorize(df.tipo_fios, sort = True)\n",
    "[df.dieta, codes_dieta] = pd.factorize(df.dieta, sort = True)\n",
    "[df.atividade_fisica, codes_atividade_fisica] = pd.factorize(df.atividade_fisica, sort = True)\n",
    "[df.frequencia_estresse, codes_frequencia_estresse] = pd.factorize(df.frequencia_estresse, sort = True)\n",
    "[df.faixa_etaria, codes_faixa_etaria] = pd.factorize(df.faixa_etaria, sort = True)\n",
    "[df.fragancia, codes_fragancia] = pd.factorize(df.fragancia, sort = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão entre features e variável alvo\n",
    "y = df.pop('target')\n",
    "X = df.copy()\n",
    "\n",
    "# Divisão do conjunto em dados de treino e de teste (70%/30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento e predição do modelo\n",
    "model = xgb.XGBClassifier(random_state = 9, \n",
    "                                max_depth = 12,\n",
    "                                n_estimators = 400,\n",
    "                                learning_rate = 1.2,\n",
    "                                subsample = 0.2,\n",
    "                                )\n",
    "eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "model.fit(X_train,y_train, verbose = False, eval_metric=[\"error\", \"logloss\"], eval_set=eval_set)\n",
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando os erros dos conjuntos de treino e teste\n",
    "results = model.evals_result()\n",
    "epochs = len(results['validation_0']['error'])\n",
    "x_axis = range(0, epochs)\n",
    "# Plot log loss\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x_axis, results['validation_0']['logloss'], label='Treino')\n",
    "ax.plot(x_axis, results['validation_1']['logloss'], label='Teste')\n",
    "ax.legend()\n",
    "plt.ylabel('Log Loss')\n",
    "plt.title('Log Loss XGBoost')\n",
    "plt.show()\n",
    "# Plot erro classificação\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x_axis, results['validation_0']['error'], label='Treino')\n",
    "ax.plot(x_axis, results['validation_1']['error'], label='Teste')\n",
    "ax.legend()\n",
    "plt.ylabel('Erro de Classificação')\n",
    "plt.title('Erro de classificação do XGBoost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curva ROC\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "plt.title('Curva ROC')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.ylabel('Taxa de Verdadeiros Positivos')\n",
    "plt.xlabel('Taxa de Falsos Positivos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eficácia no conjunto de teste\n",
    "accuracy_score(y_test,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A eficácia atingida nos casos positivos do conjunto de teste foi de 11.0%\n"
     ]
    }
   ],
   "source": [
    "x = pd.DataFrame([y_test.reset_index(drop = True),preds]).T\n",
    "obs = y_test[y_test == 1]\n",
    "eficacia_positivos = x[(x['target'] == 1) & (x['Unnamed 0'] == 1)].shape[0]/obs.shape[0]\n",
    "print('A eficácia atingida nos casos positivos do conjunto de teste foi de {0}%'.format(np.round(np.amax(eficacia_positivos)*100),2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validação cruzada\n",
    "kfold = KFold(n_splits=10)\n",
    "results = cross_val_score(model, X_train, y_train, cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('A acurácia máxima atingida através da validação cruzada por K-fold foi de {0}%'.format(np.round(np.amax(results)*100),2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('model.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9b8ea942591382cb349c47f393817917b88af7f8f0c02d4ffa9a41f75aaebb44"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
